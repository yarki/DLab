{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql._\n",
    "\n",
    "val workingBucket = \"s3a://demo-dlab21new-dmytro-liaskovskyi-bucket\"\n",
    "val sqlCtx = new SQLContext(sc)\n",
    "val hc = sc.hadoopConfiguration\n",
    "hc.set(\"hive.execution.engine\", \"mr\")\n",
    "\n",
    "def fullPath(path: String) = {\n",
    "    s\"$workingBucket/$path\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val carriers = sqlCtx.read.\n",
    "                        format(\"parquet\").\n",
    "                        load(fullPath(\"Scala_processed/carriers/\"))\n",
    "carriers.createOrReplaceTempView(\"carriers\")\n",
    "println(carriers.schema)\n",
    "carriers.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val airports = sqlCtx.read.\n",
    "                        format(\"parquet\").\n",
    "                        load(fullPath(\"Scala_processed/airports/\"))\n",
    "airports.createOrReplaceTempView(\"airports\")\n",
    "println(airports.schema)\n",
    "airports.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlCtx.implicits._\n",
    "\n",
    "val flights = sqlCtx.read.\n",
    "                        format(\"parquet\").\n",
    "                        load(fullPath(\"Scala_processed/flights/\"))\n",
    "flights.createOrReplaceTempView(\"flights\")\n",
    "println(flights.schema)\n",
    "flights.select($\"ArrDelay\",$\"CarrierDelay\",$\"WeatherDelay\",$\"Distance\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// delay = sqlContext.sql(\"\"\"\n",
    "// SELECT SUBSTR(c.description, 0, 15) as Carrier, WorkDayDelay, WeekendDelay \n",
    "// FROM\n",
    "//        (SELECT CEIL( AVG(f.ArrDelay + f.DepDelay) ) as WorkDayDelay, f.UniqueCarrier\n",
    "//         FROM flights f\n",
    "//         WHERE f.DayOfWeek < 6\n",
    "//         GROUP BY f.UniqueCarrier \n",
    "//         ORDER BY WorkDayDelay desc \n",
    "//         LIMIT 10) t\n",
    "//     JOIN\n",
    "//        (SELECT CEIL( AVG(f.ArrDelay + f.DepDelay) ) as WeekendDelay, f.UniqueCarrier\n",
    "//         FROM flights f\n",
    "//         WHERE f.DayOfWeek > 5\n",
    "//         GROUP BY f.UniqueCarrier) t1\n",
    "//       ON t.UniqueCarrier = t1.UniqueCarrier\n",
    "//     JOIN carriers c \n",
    "//       ON t.UniqueCarrier = c.code \n",
    "// ORDER BY WeekendDelay DESC, WorkDayDelay DESC\n",
    "// \"\"\").toPandas()\n",
    "\n",
    "// color_range_days = [\"#2966FF\", \"#61F2FF\"]\n",
    "// delay[\"Average\"] = (delay.WorkDayDelay + delay.WeekendDelay) / 2\n",
    "// ax = delay.Average.plot(x='Carrier', linestyle='-', marker='o')\n",
    "// delay.plot(x='Carrier', y=['WorkDayDelay','WeekendDelay'], kind='bar', legend = True,  figsize=(12, 4), color=color_range_days, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val delay = sqlCtx.sql(\"\"\"\n",
    "SELECT SUBSTR(c.description, 0, 15) as Carrier, WorkDayDelay, WeekendDelay \n",
    "FROM\n",
    "       (SELECT CEIL( AVG(f.ArrDelay + f.DepDelay) ) as WorkDayDelay, f.UniqueCarrier\n",
    "        FROM flights f\n",
    "        WHERE f.DayOfWeek < 6\n",
    "        GROUP BY f.UniqueCarrier \n",
    "        ORDER BY WorkDayDelay desc \n",
    "        LIMIT 10) t\n",
    "    JOIN\n",
    "       (SELECT CEIL( AVG(f.ArrDelay + f.DepDelay) ) as WeekendDelay, f.UniqueCarrier\n",
    "        FROM flights f\n",
    "        WHERE f.DayOfWeek > 5\n",
    "        GROUP BY f.UniqueCarrier) t1\n",
    "      ON t.UniqueCarrier = t1.UniqueCarrier\n",
    "    JOIN carriers c \n",
    "      ON t.UniqueCarrier = c.code \n",
    "ORDER BY WeekendDelay DESC, WorkDayDelay DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+------------+\n",
      "|        Carrier|WorkDayDelay|WeekendDelay|\n",
      "+---------------+------------+------------+\n",
      "|United Air Line|          25|          26|\n",
      "|JetBlue Airways|          23|          26|\n",
      "|    Comair Inc.|          22|          25|\n",
      "|Mesa Airlines I|          23|          24|\n",
      "|Atlantic Southe|          21|          24|\n",
      "|American Airlin|          26|          23|\n",
      "|AirTran Airways|          17|          22|\n",
      "|Continental Air|          26|          20|\n",
      "|Expressjet Airl|          23|          19|\n",
      "|American Eagle |          22|          17|\n",
      "+---------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from https://brunelvis.org/jar/spark-kernel-brunel-all-2.0.jar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Magic AddJar failed to execute with error: \n",
       "Connection timed out (Connection timed out)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// %AddJar -magic https://brunelvis.org/jar/spark-kernel-brunel-all-2.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached version of spark-kernel-brunel-all-2.0.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar -magic file:/tmp/spark-kernel-brunel-all-2.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Magic brunel failed to execute with error: \n",
       "org/apache/spark/sql/DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%brunel data('carriers') bar x(Description) y(#count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from file:/tmp/lightning-scala-assembly-0.1.0-SNAPSHOT.jar\n",
      "Finished download of lightning-scala-assembly-0.1.0-SNAPSHOT.jar\n"
     ]
    },
    {
     "ename": "scala.reflect.internal.FatalError",
     "evalue": "object Predef does not have a member classOf",
     "output_type": "error",
     "traceback": [
      "scala.reflect.internal.Definitions$DefinitionsClass.scala$reflect$internal$Definitions$DefinitionsClass$$fatalMissingSymbol(Definitions.scala:1186)",
      "scala.reflect.internal.Definitions$DefinitionsClass.getMember(Definitions.scala:1203)",
      "scala.reflect.internal.Definitions$DefinitionsClass.getMemberMethod(Definitions.scala:1238)",
      "scala.reflect.internal.Definitions$DefinitionsClass$RunDefinitions.Predef_classOf$lzycompute(Definitions.scala:1469)",
      "scala.reflect.internal.Definitions$DefinitionsClass$RunDefinitions.Predef_classOf(Definitions.scala:1469)",
      "scala.reflect.internal.Definitions$DefinitionsClass$RunDefinitions.isPredefClassOf(Definitions.scala:1459)",
      "scala.tools.nsc.typechecker.Typers$Typer.typedIdent$2(Typers.scala:4885)",
      "scala.tools.nsc.typechecker.Typers$Typer.typedIdentOrWildcard$1(Typers.scala:4908)",
      "scala.tools.nsc.typechecker.Typers$Typer.typedInAnyMode$1(Typers.scala:5340)",
      "scala.tools.nsc.typechecker.Typers$Typer.typed1(Typers.scala:5360)",
      "scala.tools.nsc.typechecker.Typers$Typer.runTyper$1(Typers.scala:5396)",
      "scala.tools.nsc.typechecker.Typers$Typer.scala$tools$nsc$typechecker$Typers$Typer$$typedInternal(Typers.scala:5423)",
      "scala.tools.nsc.typechecker.Typers$Typer.body$2(Typers.scala:5370)",
      "scala.tools.nsc.typechecker.Typers$Typer.typed(Typers.scala:5374)",
      "scala.tools.nsc.interpreter.ReplGlobal$$anon$1$$anon$2.typed(ReplGlobal.scala:36)",
      "scala.tools.nsc.typechecker.Typers$Typer.typedQualifier(Typers.scala:5472)",
      "scala.tools.nsc.typechecker.Typers$Typer.typedQualifier(Typers.scala:5480)",
      "scala.tools.nsc.typechecker.Typers$Typer.typedPackageDef$1(Typers.scala:5012)",
      "scala.tools.nsc.typechecker.Typers$Typer.typedMemberDef$1(Typers.scala:5312)",
      "scala.tools.nsc.typechecker.Typers$Typer.typed1(Typers.scala:5359)",
      "scala.tools.nsc.typechecker.Typers$Typer.runTyper$1(Typers.scala:5396)",
      "scala.tools.nsc.typechecker.Typers$Typer.scala$tools$nsc$typechecker$Typers$Typer$$typedInternal(Typers.scala:5423)",
      "scala.tools.nsc.typechecker.Typers$Typer.body$2(Typers.scala:5370)",
      "scala.tools.nsc.typechecker.Typers$Typer.typed(Typers.scala:5374)",
      "scala.tools.nsc.interpreter.ReplGlobal$$anon$1$$anon$2.typed(ReplGlobal.scala:36)",
      "scala.tools.nsc.typechecker.Typers$Typer.typed(Typers.scala:5448)",
      "scala.tools.nsc.typechecker.Analyzer$typerFactory$$anon$3.apply(Analyzer.scala:102)",
      "scala.tools.nsc.Global$GlobalPhase$$anonfun$applyPhase$1.apply$mcV$sp(Global.scala:440)",
      "scala.tools.nsc.Global$GlobalPhase.withCurrentUnit(Global.scala:431)",
      "scala.tools.nsc.Global$GlobalPhase.applyPhase(Global.scala:440)",
      "scala.tools.nsc.typechecker.Analyzer$typerFactory$$anon$3$$anonfun$run$1.apply(Analyzer.scala:94)",
      "scala.tools.nsc.typechecker.Analyzer$typerFactory$$anon$3$$anonfun$run$1.apply(Analyzer.scala:93)",
      "scala.collection.Iterator$class.foreach(Iterator.scala:893)",
      "scala.collection.AbstractIterator.foreach(Iterator.scala:1336)",
      "scala.tools.nsc.typechecker.Analyzer$typerFactory$$anon$3.run(Analyzer.scala:93)",
      "scala.tools.nsc.Global$Run.compileUnitsInternal(Global.scala:1501)",
      "scala.tools.nsc.Global$Run.compileUnits(Global.scala:1486)",
      "scala.tools.nsc.Global$Run.compileSources(Global.scala:1481)",
      "scala.tools.nsc.interpreter.IMain.compileSourcesKeepingRun(IMain.scala:435)",
      "scala.tools.nsc.interpreter.IMain$ReadEvalPrint.compileAndSaveRun(IMain.scala:855)",
      "scala.tools.nsc.interpreter.IMain$ReadEvalPrint.compile(IMain.scala:813)",
      "scala.tools.nsc.interpreter.IMain$Request.compile$lzycompute(IMain.scala:1002)",
      "scala.tools.nsc.interpreter.IMain$Request.compile(IMain.scala:997)",
      "scala.tools.nsc.interpreter.IMain.compile(IMain.scala:579)",
      "scala.tools.nsc.interpreter.IMain.compiled(IMain.scala:591)",
      "scala.tools.nsc.interpreter.IMain.eval(IMain.scala:1074)",
      "javax.script.AbstractScriptEngine.eval(AbstractScriptEngine.java:264)",
      "org.apache.toree.kernel.interpreter.scala.ScalaInterpreterSpecific$class.read(ScalaInterpreterSpecific.scala:262)",
      "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter.read(ScalaInterpreter.scala:43)",
      "org.apache.toree.kernel.protocol.v5.magic.PostProcessor$$anonfun$1.apply(PostProcessor.scala:29)",
      "org.apache.toree.kernel.protocol.v5.magic.PostProcessor$$anonfun$1.apply(PostProcessor.scala:29)",
      "scala.Option.flatMap(Option.scala:171)",
      "org.apache.toree.kernel.protocol.v5.magic.PostProcessor.process(PostProcessor.scala:29)",
      "org.apache.toree.kernel.protocol.v5.relay.ExecuteRequestRelay$$anonfun$org$apache$toree$kernel$protocol$v5$relay$ExecuteRequestRelay$$packageFutureResponse$1.apply(ExecuteRequestRelay.scala:81)",
      "org.apache.toree.kernel.protocol.v5.relay.ExecuteRequestRelay$$anonfun$org$apache$toree$kernel$protocol$v5$relay$ExecuteRequestRelay$$packageFutureResponse$1.apply(ExecuteRequestRelay.scala:78)",
      "scala.util.Success$$anonfun$map$1.apply(Try.scala:237)",
      "scala.util.Try$.apply(Try.scala:192)",
      "scala.util.Success.map(Try.scala:237)",
      "scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)",
      "scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)",
      "scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)",
      "akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)",
      "akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91)",
      "akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)",
      "akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91)",
      "scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)",
      "akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90)",
      "akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39)",
      "akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:409)",
      "scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)",
      "scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)",
      "scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)",
      "scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)"
     ]
    }
   ],
   "source": [
    "%AddJar file:/tmp/lightning-scala-assembly-0.1.0-SNAPSHOT.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from file:/tmp/wisp_2.11.jar\n",
      "Finished download of wisp_2.11.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar file:/tmp/wisp_2.11.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.viz.lightning.Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import com.quantifind.charts.Highcharts._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: error: missing or invalid dependency detected while loading class file 'WebPlot.class'.\n",
       "Could not access term unfiltered in package <root>,\n",
       "because it (or its dependencies) are missing. Check your build definition for\n",
       "missing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.)\n",
       "A full rebuild may help if 'WebPlot.class' was compiled against an incompatible version of <root>.\n",
       "StackTrace: "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areaspline(List(1, 2, 3, 4, 5), List(4, 1, 3, 2, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking io.continuum.bokeh:bokeh:0.6 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps6959302001006243656/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> Failed to resolve io.continuum.bokeh:bokeh:0.6\n",
      "    -> not found: /tmp/toree_add_deps6959302001006243656/cache/io.continuum.bokeh/bokeh/ivy-0.6.xml\n",
      "    -> download error: Caught java.net.ConnectException: Connection timed out (Connection timed out) (Connection timed out (Connection timed out))\n"
     ]
    }
   ],
   "source": [
    "%AddDeps io.continuum.bokeh bokeh 0.6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala (Spark-2.0.2) [demo-dlab21new-dmytro_liaskovskyi-emr-jupyter-52010-e3750]",
   "language": "scala",
   "name": "toree_demo-dlab21new-dmytro_liaskovskyi-emr-jupyter-52010-e3750"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
